{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/test/tensorboard2/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.common.policies import CnnPolicy, MlpLstmPolicy, CnnLstmPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines import A2C\n",
    "from stable_baselines.common import set_global_seeds\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.callbacks import CheckpointCallback\n",
    "from stable_baselines.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from stable_baselines.logger import configure\n",
    "from stable_baselines.common.callbacks import BaseCallback\n",
    "import tensorflow as tf\n",
    "import pdb \n",
    "from stable_baselines.bench import Monitor\n",
    "import os\n",
    "import subprocess\n",
    "import supervised_utils\n",
    "import evaluate_policy\n",
    "import custom_cnn_lstm\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\stable_baselines\\common\\tf_layers.py:103: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:187: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\witten_goat\\Anaconda3\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:199: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = DummyVecEnv([lambda: gym.make('vrgym-v0')])\n",
    "policy_kwargs = dict(n_lstm=64, cnn_extractor = custom_cnn_lstm.nature_cnn_best_rewinput)\n",
    "\n",
    "model = A2C(CnnLstmPolicy, env, verbose =1, policy_kwargs = policy_kwargs,  \n",
    "        learning_rate = 2.5e-4, n_steps=140)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path =  './logs/VA_maze_v5/'\n",
    "params = evaluate_policy.get_params_from_zip(load_path + 'checkpoints/rl_model_20800000_steps')\n",
    "# NEED TO FIX YPOS IN THE EVALUATE! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[actions, rewards, obses0, feats, terms, vs, tow_counts, episode_lengths, ypos] = evaluate_policy.get_model_data(model, env, \n",
    "                                                                            n_eval_episodes = 1000 , by_ep = True, obses_ep_saved = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([actions, rewards, feats,  terms, vs, tow_counts, episode_lengths] , open(load_path + '5000t_mosttrain_nova_db_p1.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([obses0], open(load_path + '1000t_obses_nova.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking everything is right before going on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[actions, rewards, obses, feats, terms, vs, tow_counts, episode_lengths, ypos] = evaluate_policy.get_model_data(model, env, \n",
    "                                                                            n_eval_episodes = 1000 , by_ep = True, obses_ep_saved = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([actions, rewards, feats,  terms, vs, tow_counts, episode_lengths, ypos] , open(load_path + '5000t_mosttrain_nova_db_p2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[actions, rewards, obses, feats, terms, vs, tow_counts, episode_lengths, ypos] = evaluate_policy.get_model_data(model, env, \n",
    "                                                                            n_eval_episodes = 1000 , by_ep = True, obses_ep_saved = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([actions, rewards, feats,  terms, vs, tow_counts, episode_lengths, ypos] , open(load_path + '5000t_mosttrain_nova_db_p3.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[actions, rewards, obses, feats, terms, vs, tow_counts, episode_lengths, ypos] = evaluate_policy.get_model_data(model, env, \n",
    "                                                                            n_eval_episodes = 1000 , by_ep = True, obses_ep_saved = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([actions, rewards, feats,  terms, vs, tow_counts, episode_lengths, ypos] , open(load_path + '5000t_mosttrain_nova_db_p4.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[actions, rewards, obses, feats, terms, vs, tow_counts, episode_lengths, ypos] = evaluate_policy.get_model_data(model, env, \n",
    "                                                                            n_eval_episodes = 1000 , by_ep = True, obses_ep_saved = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([actions, rewards, feats,  terms, vs, tow_counts, episode_lengths, ypos] , open(load_path + '5000t_mosttrain_nova_db_p5.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 hr 33 min # WHY %%time. WTF! it's 4 hours and 30 min for 2500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[actions, rewards, obses, feats, terms, vs, tow_counts, episode_lengths, ypos] = pickle.load( open(load_path + '5000t_80perf.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obses[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(obses0[501][120,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_rew = np.array([np.sum(t) for t in rewards])\n",
    "ep_tow = np.array([np.max(t, 0) for t in tow_counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mean_reward:{np.mean(ep_rew):.2f} +/- {np.std(ep_rew):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_towers = np.where(ep_tow[:,0] == ep_tow[:, 1])\n",
    "not_equal = np.where(ep_tow[:,0] - ep_tow[:,1])\n",
    "not_equal_wrong = np.where((ep_tow[:,0] - ep_tow[:,1]) * (1 - ep_rew)) \n",
    "no_diff = np.where(np.abs(ep_tow[:,0] - ep_tow[:,1]) == 0)\n",
    "\n",
    "small_diff = np.where(np.abs(ep_tow[:,0] - ep_tow[:,1]) == 1)\n",
    "med_diff = np.where(np.abs(ep_tow[:,0] - ep_tow[:,1]) == 2)\n",
    "\n",
    "big_diff = np.where(np.abs(ep_tow[:,0] - ep_tow[:,1]) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = np.arange(0,10)\n",
    "perf = []\n",
    "num_trials = []\n",
    "for diff in diffs:\n",
    "    idx = np.where(np.abs(ep_tow[:,0] - ep_tow[:,1]) == diff)\n",
    "    if len(idx[0]) == 0:\n",
    "        break;\n",
    "    else:\n",
    "        perf.append(np.mean(ep_rew[idx]))\n",
    "        num_trials.append(len(idx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(len(perf)), perf)\n",
    "plt.xlabel(\"Difference in tower\")\n",
    "plt.ylabel(\"performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path =  './logs/cnnlstm_rewinput_cont/'\n",
    "params = evaluate_policy.get_params_from_zip(load_path + 'checkpoints/rl_model_24000000_steps')\n",
    "# to change; edit vr_env to have 5 actions and the right set up. git checkout for tankmousevr the older version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_last_steps = np.vstack([t[-20:] for t in vs])\n",
    "reward_last_steps = np.vstack(t[-20:] for t in rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(reward_last_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(value_last_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(np.arange(-9, 11), np.nanmean(value_last_steps[ep_rew == 1 , :],0),  label = 'Rewarded')\n",
    "plt.plot(np.arange(-9, 11), np.nanmean(value_last_steps[ep_rew == 0 , :],0),  label = 'UnRewarded')\n",
    "plt.legend()\n",
    "plt.title(\"Value at Rew Time\")\n",
    "plt.xlabel (\"Time from Reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tow_counts_wrong = tow_[not_equal_wrong]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[graph, sess] = model.get_graph_and_sess()\n",
    "# [n.name for n in graph.as_graph_def().node]\n",
    "#Relu_3 is feature output from cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    state_ph_shape = graph.get_tensor_by_name(\"input_1/states_ph:0\").shape\n",
    "    dones_ph_shape = graph.get_tensor_by_name(\"input_1/dones_ph:0\").shape\n",
    "    reward = 0\n",
    "    r2,  o1, o2, vs1, vs2 = [],[],[], [], []\n",
    "    \n",
    "    for ep in range(1):\n",
    "        obs = env.reset()\n",
    "        done = np.zeros((dones_ph_shape))\n",
    "        state = np.zeros((state_ph_shape))\n",
    "        ep_len = 0\n",
    "        while not done:\n",
    "            vs1.append(model.value(obs, state = state, mask = done))\n",
    "            act_pre = graph.get_tensor_by_name(\"model/Reshape_1:0\").eval(\n",
    "                {\"input/Ob:0\":obs, \"input_1/dones_ph:0\":done\n",
    "                , \"input_1/states_ph:0\":state}, session = sess)\n",
    "            o1.append(np.squeeze(act_pre[:,:,-2:]))\n",
    "\n",
    "            action, state = model.predict(obs, state=state)\n",
    "\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            act = graph.get_tensor_by_name(\"model/Reshape_1:0\").eval(\n",
    "                {\"input/Ob:0\":obs, \"input_1/dones_ph:0\":done\n",
    "                , \"input_1/states_ph:0\":state}, session = sess)\n",
    "            vs2.append(model.value(obs, state = state, mask = done))\n",
    "\n",
    "            o2.append(np.squeeze(act[:,:,-2:]))\n",
    "            r2.append(reward)\n",
    "            ep_len = ep_len + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.vstack(o2)[:,1])\n",
    "plt.plot(r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({'o1':o1, 'v1':vs1, 'r2':r2, 'o2':o2, 'vs2':vs2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[290:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs1[140:150]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(o1)[140:150,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs2[140:150]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2[140:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
